# `ZooKeeper`分布式协调服务

`ZooKeeper`是一个分布式的应用程序协调服务，我们client在调用RPC框架服务的时候需要一个服务配置中心来记录那个服务器提供了那个服务，通俗些讲就是client需要知道他想要远程调用的服务被放在了哪一台服务器上他的`IP:PORT`是什么，所以我们需要一个中间件`ZooKeeper`来告诉client他想要调用的服务在哪。

## `ZooKeeper`提供了什么

正如上文所说，`zookeeper`为我们提供文件系统和通知机制

- 文件系统

  `zookeeper`提供了一个多层级的命名空间（结点znode）。与文件系统不同的是，这些结点都可以设置一个关联的数据，而文件系统只有叶子结点可以存放数据目录结点则不行。`zookeeper`为了保持高吞吐了低延迟，在内存中维护了这个树状的树形结构。这种特质的原因使得`zookeeper`每个结点只能存储1MB的数据。

- 通知机制
  - client端会对某一个znode建立一个`watcher`事件，当znode发生变化时，client会接收到zk发过来的通知，从而根据znode的变化做出业务上的改变。

## 结点类型

`zookeeper`节点类型可以分为持久节点（PERSISTENT）、临时节点（EPHEMERAL）和顺序节点（SEQUENTIAL）三大类，而本项目只会用到前两类。

### 持久节点（PERSISTENT）

所谓持久性结点就是指该数据节点被创建了之后，会一直保留在`zookeeper`服务器上，直到有删除操作来主动清除这个节点。例如项目中的`service_name`也就是`/FriendSerciceRpc`就会被注册为持久结点，这里即使RPC结点超时未发送`心跳`，zk也不会删除这个结点。（心跳概念见下文）

### 临时节点（EPHEMERAL）

和持久性节点不同的是，临时结点的生命周期和客户端的会话绑定在一起的。因此只要客户端会话失效，那么这个节点就会被自动清理掉。注意，这里提到的是客户端会话失效，而非TCP连接断开。同时`zookeeper`规定了不能在临时结点上创建子结点，即临时结点只能作为叶子结点。我们这里做一个测试。

- 通过自述文件的方法启动`zookeeper`。（这里不做演示）

- 启动`provider`发布服务到zk上，这里能看到我们已经发布成功了。

  ```c++
  ubuntu% ./provider -i test.conf 
  rpcserverip:127.0.0.1
  rpcserverport:8080
  zookeeperip:127.0.0.1
  zookeeperport:2181
  2023-04-23 00:00:22,262:4806(0x7f7333731a00):ZOO_INFO@log_env@726: Client environment:zookeeper.version=zookeeper C client 3.4.10
  2023-04-23 00:00:22,262:4806(0x7f7333731a00):ZOO_INFO@log_env@730: Client environment:host.name=ubuntu
  2023-04-23 00:00:22,262:4806(0x7f7333731a00):ZOO_INFO@log_env@737: Client environment:os.name=Linux
  2023-04-23 00:00:22,262:4806(0x7f7333731a00):ZOO_INFO@log_env@738: Client environment:os.arch=5.4.0-146-generic
  2023-04-23 00:00:22,262:4806(0x7f7333731a00):ZOO_INFO@log_env@739: Client environment:os.version=#163~18.04.1-Ubuntu SMP Mon Mar 20 15:02:59 UTC 2023
  2023-04-23 00:00:22,263:4806(0x7f7333731a00):ZOO_INFO@log_env@747: Client environment:user.name=zixuanhuang
  2023-04-23 00:00:22,263:4806(0x7f7333731a00):ZOO_INFO@log_env@755: Client environment:user.home=/home/zixuanhuang
  2023-04-23 00:00:22,263:4806(0x7f7333731a00):ZOO_INFO@log_env@767: Client environment:user.dir=/home/zixuanhuang/mprpc/bin
  2023-04-23 00:00:22,263:4806(0x7f7333731a00):ZOO_INFO@zookeeper_init@800: Initiating client connection, host=127.0.0.1:2181 sessionTimeout=30000 watcher=0x55c06a84ef18 sessionId=0 sessionPasswd=<null> context=(nil) flags=0
  2023-04-23 00:00:22,263:4806(0x7f7330ecf700):ZOO_INFO@check_events@1728: initiated connection to server [127.0.0.1:2181]
  2023-04-23 00:00:22,266:4806(0x7f7330ecf700):ZOO_INFO@check_events@1775: session establishment complete on server [127.0.0.1:2181], sessionId=0x1879d16838c0045, negotiated timeout=30000
  zookeeper_init sucess!
  znode create success... path:/FriendServiceRpc
  znode create success... path:/FriendServiceRpc/GetFriendsList
  ```

- 回到`zkcli.sh`查看是否注册了这个节点，可以看到已经注册成功了。

  ```c++
  [zk: localhost:2181(CONNECTED) 6] ls /
  [zookeeper, FriendServiceRpc]
  [zk: localhost:2181(CONNECTED) 7] ls /FriendServiceRpc/GetFriendsList
  []
  [zk: localhost:2181(CONNECTED) 8] 
  ```

- 这个时候我们将`provider`的会话关掉，可以看到`/FriendServiceRpc`目录下已经为空。

  ```c++
  provider:
  ^C
  ubuntu% 
  zkcli.sh:
  [zk: localhost:2181(CONNECTED) 8] ls /
  [zookeeper, FriendServiceRpc]
  [zk: localhost:2181(CONNECTED) 9] ls /FriendServiceRpc
  []
  ```

## 心跳消息

client和ZooKeeper之间通信，需要创建一个Session，这个Session会有一个超时时间，因为Zookeeper集群会把Client的Session信息持久化，所以在Session没超时之前，client与Zookeeper server的连接可以在各个Zookeeper server之间透明地移动。在实际的应用中，如果client与server之间的通信足够频繁，Session的维护就不需要其他额外的消息了。否则，ZooKeeper client每t/3ms就需要发一次心跳给Service，如果超过了t的事件Service还没有接收到client发过来的心跳消息，那么ZooKeeper Service就会认为这个client失效了，从而注销掉他的服务。

## `ZooKeeper`组织结构

![](https://github.com/terryup/rpc/blob/mprpc/%E6%B3%A8%E5%86%8C%E4%B8%AD%E5%BF%83.png)

## 远程zkClient API存在的问题

1. 设置监听watcher只能是一次性的，每次触发后需要重复设置
2. .znode节点只存储简单的byte字节数组，如果存储对象，需要自己转换对象生成字节数组

## 项目应用

Roc_provider中注册到了unordered_map中，这里需要连接ZkClient，注册到ZooKeeper中。这里需要创建指定的路径和数据。

路径为：`/FriendServiceRpc/GetFriendList`

数据为：`127.0.0.1:2181`

#### 对于提供RPC服务端，在`RpcProvider`的`Run()`方法做以下修改

```c++
		ZkClient zkcli;
    zkcli.Start();
    for(auto &sp : m_serviceMap){
        std::string service_path = "/" + sp.first;
        zkcli.Create(service_path.c_str(), nullptr, 0);
        for(auto &mp : sp.second.m_methodMap){
            std::string method_name = service_path + "/" + mp.first;
            char method_path_data[128] = {0};
            sprintf(method_path_data, "%s:%d", ip.c_str(), port);
            zkcli.Create(method_name.c_str(), method_path_data, strlen(method_path_data), ZOO_EPHEMERAL);
        }
    }
```

#### 对于调用RPC方法的客户端，在`MprpcChannel`的`CallMethod`方法做以下修改

```c++
		ZkClient zkcli;
    zkcli.Start();
    std::string method_path = "/" + service_name + "/" + method_name;
    std::string host_data = zkcli.GetData(method_path.c_str());
    if(host_data == ""){
        controller->SetFailed(method_path + "is not exist!");
        return;
    }
    int idx = host_data.find(":");
    if(idx == -1){
        controller->SetFailed(method_path + "address is invalid!");
        return;
    }
    std::string ip = host_data.substr(0, idx);
    uint16_t port = atoi(host_data.substr(idx + 1, host_data.size() - idx).c_str());

```



